{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company, and need to know whether the company\n",
    "is in near-term danger of not being able to repay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import imblearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API for students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages I used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data.\n",
    "\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt` is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date shape:  (4818, 66)\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATA_DIR = \"./Data\"\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    DATA_DIR = \"../resource/asnlib/publicdata/bankruptcy/data\"\n",
    "\n",
    "data_file = \"5th_yr.csv\"\n",
    "data = pd.read_csv( os.path.join(DATA_DIR, \"train\", data_file) )\n",
    "\n",
    "target_attr = \"Bankrupt\"\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Date shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...        X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...   0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...  -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...   0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...   0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...   0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4818 non-null   object \n",
      " 1   X2        4818 non-null   object \n",
      " 2   X3        4818 non-null   object \n",
      " 3   X4        4818 non-null   object \n",
      " 4   X5        4818 non-null   object \n",
      " 5   X6        4818 non-null   object \n",
      " 6   X7        4818 non-null   object \n",
      " 7   X8        4818 non-null   object \n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4818 non-null   object \n",
      " 10  X11       4818 non-null   object \n",
      " 11  X12       4818 non-null   object \n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4818 non-null   object \n",
      " 14  X15       4818 non-null   object \n",
      " 15  X16       4818 non-null   object \n",
      " 16  X17       4818 non-null   object \n",
      " 17  X18       4818 non-null   object \n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4818 non-null   object \n",
      " 21  X22       4818 non-null   object \n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4818 non-null   object \n",
      " 24  X25       4818 non-null   object \n",
      " 25  X26       4818 non-null   object \n",
      " 26  X27       4818 non-null   object \n",
      " 27  X28       4818 non-null   object \n",
      " 28  X29       4818 non-null   object \n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4818 non-null   object \n",
      " 32  X33       4818 non-null   object \n",
      " 33  X34       4818 non-null   object \n",
      " 34  X35       4818 non-null   object \n",
      " 35  X36       4818 non-null   object \n",
      " 36  X37       4818 non-null   object \n",
      " 37  X38       4818 non-null   object \n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4818 non-null   object \n",
      " 40  X41       4818 non-null   object \n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4818 non-null   object \n",
      " 45  X46       4818 non-null   object \n",
      " 46  X47       4818 non-null   object \n",
      " 47  X48       4818 non-null   object \n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4818 non-null   object \n",
      " 50  X51       4818 non-null   object \n",
      " 51  X52       4818 non-null   object \n",
      " 52  X53       4818 non-null   object \n",
      " 53  X54       4818 non-null   object \n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4818 non-null   object \n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4818 non-null   object \n",
      " 59  X60       4818 non-null   object \n",
      " 60  X61       4818 non-null   object \n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4818 non-null   object \n",
      " 63  X64       4818 non-null   object \n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float64`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you might want to first convert all attributes to numeric\n",
    "\n",
    "**Hint**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your submission on a test dataset that we provide\n",
    "- It has no labels, so **you** can't use it to evaluate your model, but **we** have the labels\n",
    "- We will call this evaluation dataset the \"holdout\" data\n",
    "\n",
    "Let's get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1092, 65)\n"
     ]
    }
   ],
   "source": [
    "holdout_data = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "print(\"Data shape: \", holdout_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model on the holdout examples using metrics\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "From our lecture: we may have to make a trade-off between Recall and Precision.\n",
    "\n",
    "Our evaluation of your submission will be partially based on how you made (and described) the trade-off.\n",
    "\n",
    "You may assume that it is 5 times worse to *fail to identify a company that will go bankrupt*\n",
    "than it is to fail to identify a company that won't go bankrupt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your model\n",
    "\n",
    "Time for you to continue the Recipe for Machine Learning on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convert data type into numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4816 non-null   float64\n",
      " 1   X2        4816 non-null   float64\n",
      " 2   X3        4816 non-null   float64\n",
      " 3   X4        4803 non-null   float64\n",
      " 4   X5        4808 non-null   float64\n",
      " 5   X6        4816 non-null   float64\n",
      " 6   X7        4816 non-null   float64\n",
      " 7   X8        4804 non-null   float64\n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4816 non-null   float64\n",
      " 10  X11       4816 non-null   float64\n",
      " 11  X12       4803 non-null   float64\n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4816 non-null   float64\n",
      " 14  X15       4812 non-null   float64\n",
      " 15  X16       4804 non-null   float64\n",
      " 16  X17       4804 non-null   float64\n",
      " 17  X18       4816 non-null   float64\n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4744 non-null   float64\n",
      " 21  X22       4816 non-null   float64\n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4702 non-null   float64\n",
      " 24  X25       4816 non-null   float64\n",
      " 25  X26       4804 non-null   float64\n",
      " 26  X27       4513 non-null   float64\n",
      " 27  X28       4735 non-null   float64\n",
      " 28  X29       4816 non-null   float64\n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4776 non-null   float64\n",
      " 32  X33       4803 non-null   float64\n",
      " 33  X34       4804 non-null   float64\n",
      " 34  X35       4816 non-null   float64\n",
      " 35  X36       4816 non-null   float64\n",
      " 36  X37       2750 non-null   float64\n",
      " 37  X38       4816 non-null   float64\n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4803 non-null   float64\n",
      " 40  X41       4756 non-null   float64\n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4598 non-null   float64\n",
      " 45  X46       4803 non-null   float64\n",
      " 46  X47       4787 non-null   float64\n",
      " 47  X48       4816 non-null   float64\n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4804 non-null   float64\n",
      " 50  X51       4816 non-null   float64\n",
      " 51  X52       4786 non-null   float64\n",
      " 52  X53       4735 non-null   float64\n",
      " 53  X54       4735 non-null   float64\n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4816 non-null   float64\n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4816 non-null   float64\n",
      " 59  X60       4598 non-null   float64\n",
      " 60  X61       4806 non-null   float64\n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4803 non-null   float64\n",
      " 63  X64       4735 non-null   float64\n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(64), int64(2)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are many missing value in the data set after converting into numeric data, so we need to deal with it before we train the model. I decide to remove this feature from the data. For other features, I decide to fill the median of each feature into missing places because median is more robust to outliers than mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_data(data):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    pipeline = Pipeline([(\"SimpleImputer\", imp),(\"Scale\", StandardScaler())])\n",
    "    data_t = data\n",
    "    for i in data_t.columns[0:64]:\n",
    "        data_t[[i]] = pipeline.fit_transform(data_t[[i]])\n",
    "    return data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4818 non-null   float64\n",
      " 1   X2        4818 non-null   float64\n",
      " 2   X3        4818 non-null   float64\n",
      " 3   X4        4818 non-null   float64\n",
      " 4   X5        4818 non-null   float64\n",
      " 5   X6        4818 non-null   float64\n",
      " 6   X7        4818 non-null   float64\n",
      " 7   X8        4818 non-null   float64\n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4818 non-null   float64\n",
      " 10  X11       4818 non-null   float64\n",
      " 11  X12       4818 non-null   float64\n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4818 non-null   float64\n",
      " 14  X15       4818 non-null   float64\n",
      " 15  X16       4818 non-null   float64\n",
      " 16  X17       4818 non-null   float64\n",
      " 17  X18       4818 non-null   float64\n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4818 non-null   float64\n",
      " 21  X22       4818 non-null   float64\n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4818 non-null   float64\n",
      " 24  X25       4818 non-null   float64\n",
      " 25  X26       4818 non-null   float64\n",
      " 26  X27       4818 non-null   float64\n",
      " 27  X28       4818 non-null   float64\n",
      " 28  X29       4818 non-null   float64\n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4818 non-null   float64\n",
      " 32  X33       4818 non-null   float64\n",
      " 33  X34       4818 non-null   float64\n",
      " 34  X35       4818 non-null   float64\n",
      " 35  X36       4818 non-null   float64\n",
      " 36  X37       4818 non-null   float64\n",
      " 37  X38       4818 non-null   float64\n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4818 non-null   float64\n",
      " 40  X41       4818 non-null   float64\n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4818 non-null   float64\n",
      " 45  X46       4818 non-null   float64\n",
      " 46  X47       4818 non-null   float64\n",
      " 47  X48       4818 non-null   float64\n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4818 non-null   float64\n",
      " 50  X51       4818 non-null   float64\n",
      " 51  X52       4818 non-null   float64\n",
      " 52  X53       4818 non-null   float64\n",
      " 53  X54       4818 non-null   float64\n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4818 non-null   float64\n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4818 non-null   float64\n",
      " 59  X60       4818 non-null   float64\n",
      " 60  X61       4818 non-null   float64\n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4818 non-null   float64\n",
      " 63  X64       4818 non-null   float64\n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(64), int64(2)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "data = trans_data(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all column with numeric data, so we can go into the next step.\n",
    "# Let's create train and test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X should be the 64 columns that contains different information about companys. And y should just be whether the company has bankrupcy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012021</td>\n",
       "      <td>-0.096087</td>\n",
       "      <td>-0.103121</td>\n",
       "      <td>-0.038036</td>\n",
       "      <td>-0.006126</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>-0.041039</td>\n",
       "      <td>-0.308567</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085603</td>\n",
       "      <td>0.113242</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>-0.108583</td>\n",
       "      <td>-0.023624</td>\n",
       "      <td>-0.015169</td>\n",
       "      <td>-0.082377</td>\n",
       "      <td>-0.005784</td>\n",
       "      <td>-0.062392</td>\n",
       "      <td>-0.062768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004676</td>\n",
       "      <td>-0.268714</td>\n",
       "      <td>0.249124</td>\n",
       "      <td>-0.007300</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>-0.018921</td>\n",
       "      <td>-0.444998</td>\n",
       "      <td>0.065533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339007</td>\n",
       "      <td>-0.098772</td>\n",
       "      <td>-0.007430</td>\n",
       "      <td>0.063191</td>\n",
       "      <td>-0.032173</td>\n",
       "      <td>-0.015166</td>\n",
       "      <td>-0.074409</td>\n",
       "      <td>-0.066265</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>-0.053953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012782</td>\n",
       "      <td>-0.072495</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>-0.033996</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.045266</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>-0.044286</td>\n",
       "      <td>-0.392286</td>\n",
       "      <td>-0.026973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050400</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>-0.010217</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>-0.015033</td>\n",
       "      <td>-0.187176</td>\n",
       "      <td>-0.031922</td>\n",
       "      <td>-0.051212</td>\n",
       "      <td>-0.060536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016033</td>\n",
       "      <td>-0.396555</td>\n",
       "      <td>0.278164</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.026558</td>\n",
       "      <td>0.015008</td>\n",
       "      <td>0.046886</td>\n",
       "      <td>-0.410683</td>\n",
       "      <td>0.026743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228298</td>\n",
       "      <td>-0.038299</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>-0.043069</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>-0.081043</td>\n",
       "      <td>-0.056477</td>\n",
       "      <td>-0.015816</td>\n",
       "      <td>-0.063237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.051360</td>\n",
       "      <td>-0.036607</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>-0.043124</td>\n",
       "      <td>-0.213899</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114672</td>\n",
       "      <td>-0.100887</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>0.042544</td>\n",
       "      <td>-0.039955</td>\n",
       "      <td>-0.015199</td>\n",
       "      <td>-0.055464</td>\n",
       "      <td>-0.027600</td>\n",
       "      <td>-0.053864</td>\n",
       "      <td>-0.060355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0  0.012021 -0.096087 -0.103121 -0.038036 -0.006126  0.062188  0.010124   \n",
       "1  0.004676 -0.268714  0.249124 -0.007300  0.000105  0.016518  0.002215   \n",
       "2  0.012782 -0.072495  0.005215 -0.033996  0.000682  0.045266  0.012189   \n",
       "3  0.016033 -0.396555  0.278164  0.057057  0.017578  0.026558  0.015008   \n",
       "4  0.008379 -0.030035 -0.051360 -0.036607 -0.003817  0.009006  0.006484   \n",
       "\n",
       "         X8        X9       X10  ...       X55       X56       X57       X58  \\\n",
       "0 -0.041039 -0.308567  0.003492  ... -0.085603  0.113242  0.003624 -0.108583   \n",
       "1 -0.018921 -0.444998  0.065533  ...  0.339007 -0.098772 -0.007430  0.063191   \n",
       "2 -0.044286 -0.392286 -0.026973  ... -0.050400 -0.008166  0.007522 -0.010217   \n",
       "3  0.046886 -0.410683  0.026743  ...  0.228298 -0.038299  0.008651  0.014195   \n",
       "4 -0.043124 -0.213899 -0.000182  ... -0.114672 -0.100887 -0.002878  0.042544   \n",
       "\n",
       "        X59       X60       X61       X62       X63       X64  \n",
       "0 -0.023624 -0.015169 -0.082377 -0.005784 -0.062392 -0.062768  \n",
       "1 -0.032173 -0.015166 -0.074409 -0.066265  0.040057 -0.053953  \n",
       "2 -0.003196 -0.015033 -0.187176 -0.031922 -0.051212 -0.060536  \n",
       "3 -0.043069 -0.015163 -0.081043 -0.056477 -0.015816 -0.063237  \n",
       "4 -0.039955 -0.015199 -0.055464 -0.027600 -0.053864 -0.060355  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:,'X1':'X64']\n",
    "y = data['Bankrupt']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose a test size of 0.1 to split the test and train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4336, 64)\n",
      "X_test shape:  (482, 64)\n",
      "y_train shape:  (4336,)\n",
      "y_test shape:  (482,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the model\n",
    "Let use logistic regression to do a simple training on the model. Choose \"liblinear\" as the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(solver=\"liblinear\", max_iter=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and get the in sample accuracy score. Use cross validation to check the performance, since we only have one set test data. Then evaluate the model using test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, name, X_train, X_test, y_train, y_test):\n",
    "    _ = model.fit(X_train, y_train)\n",
    "    score_in_sample = accuracy_score(model.predict(X_train),y_train)\n",
    "    k = 5\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=k)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    balance_test = balanced_accuracy_score(y_test, y_pred)\n",
    "    recall_test = recall_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "    precision_test = precision_score(y_test,   y_pred, pos_label=1, average=\"binary\")\n",
    "    print(\"Model: {m:s} class balanced Acccuracy={s:3.4f}\\n\".format(m=name, s=balance_test))\n",
    "    print(\"Model: {m:s} in sample score={s:3.4f}\\n\".format(m=name, s=score_in_sample))\n",
    "    print(\"Model: {m:s} avg cross validation score={s:3.4f}\\n\".format(m=name, s=cross_val_scores.mean()))\n",
    "    print(\"Model: {m:s} Accuracy: {a:3.2%}, Recall {r:3.2%}, Precision {p:3.2%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,r=recall_test,p=precision_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a in sample accuracy score of 0.938, cross validation score of 0.932, and out sample score of 0.932 with the logistic regression model. Recall and precision are also bad, so next I will use some other model to see if scores would increase. Also the balanced accuracy is only 0.5, it means this is a imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression class balanced Acccuracy=0.5573\n",
      "\n",
      "Model: Logistic Regression in sample score=0.9393\n",
      "\n",
      "Model: Logistic Regression avg cross validation score=0.9334\n",
      "\n",
      "Model: Logistic Regression Accuracy: 93.36%, Recall 12.12%, Precision 57.14%\n"
     ]
    }
   ],
   "source": [
    "get_score(clf,\"Logistic Regression\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try change a regularization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 is much better than L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression class balanced Acccuracy=0.5247\n",
      "\n",
      "Model: Logistic Regression in sample score=0.9410\n",
      "\n",
      "Model: Logistic Regression avg cross validation score=0.9347\n",
      "\n",
      "Model: Logistic Regression Accuracy: 92.53%, Recall 6.06%, Precision 28.57%\n"
     ]
    }
   ],
   "source": [
    "get_score(clf,\"Logistic Regression\", X_train, X_test, y_train, y_test)\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(solver=\"liblinear\", max_iter=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Support Vector Machine\n",
    "Let's try use SVM to see if we have a better prediction on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = make_pipeline(StandardScaler(), SVC(kernel='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced accruacy decreased. Other accuracy scores remain the same level, recall and precision are 0 because it's SVM model. We can see from the accuracy results that using SVM doesn't have difference compare to logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Classification class balanced Acccuracy=0.4989\n",
      "\n",
      "Model: Support Vector Classification in sample score=0.9384\n",
      "\n",
      "Model: Support Vector Classification avg cross validation score=0.9354\n",
      "\n",
      "Model: Support Vector Classification Accuracy: 92.95%, Recall 0.00%, Precision 0.00%\n"
     ]
    }
   ],
   "source": [
    "get_score(svc, \"Support Vector Classification\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Classification class balanced Acccuracy=0.5140\n",
      "\n",
      "Model: Support Vector Classification in sample score=0.9384\n",
      "\n",
      "Model: Support Vector Classification avg cross validation score=0.9359\n",
      "\n",
      "Model: Support Vector Classification Accuracy: 93.15%, Recall 3.03%, Precision 50.00%\n"
     ]
    }
   ],
   "source": [
    "svc = make_pipeline(StandardScaler(), SVC(C=0.1, kernel='linear'))\n",
    "get_score(svc, \"Support Vector Classification\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing penalty paracter C to 0.1 (10 times smaller), found out that we increaed precision but recall still very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Since SVM's accuracy scores have very small improvements, I will try gradient descent to see if it can increase scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = make_pipeline(StandardScaler(), SGDClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced accuracy score increased to 0.6 which is very good. Other accuracy socres remain the same level. Recall increased to 30%, but precision decreased 20% compare to logistic model. However, I don't know why but each time I run the code, I will get different recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Descent class balanced Acccuracy=0.5787\n",
      "\n",
      "Model: Gradient Descent in sample score=0.9269\n",
      "\n",
      "Model: Gradient Descent avg cross validation score=0.9225\n",
      "\n",
      "Model: Gradient Descent Accuracy: 92.12%, Recall 18.18%, Precision 35.29%\n"
     ]
    }
   ],
   "source": [
    "get_score(sgd, \"Gradient Descent\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "Because balanced accuracy of data is low, I decide to use gradient boosting classifier because this model is not sensitive to imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balanced accuracy score increased to 0.709. Also, all accuracy scores are the highest. Recall is still low but has a increase, precision looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boosting Classifier class balanced Acccuracy=0.7380\n",
      "\n",
      "Model: Gradient Boosting Classifier in sample score=0.9818\n",
      "\n",
      "Model: Gradient Boosting Classifier avg cross validation score=0.9571\n",
      "\n",
      "Model: Gradient Boosting Classifier Accuracy: 95.64%, Recall 48.48%, Precision 80.00%\n"
     ]
    }
   ],
   "source": [
    "get_score(gbc, \"Gradient Boosting Classifier\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifer\n",
    "This is also a classifer that robust to imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest Classifier class balanced Acccuracy=0.5876\n",
      "\n",
      "Model: Random Forest Classifier in sample score=1.0000\n",
      "\n",
      "Model: Random Forest Classifier avg cross validation score=0.9442\n",
      "\n",
      "Model: Random Forest Classifier Accuracy: 93.78%, Recall 18.18%, Precision 66.67%\n"
     ]
    }
   ],
   "source": [
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42, n_jobs=2))\n",
    "get_score(rf, \"Random Forest Classifier\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "One way of handling imbalanced data is using class wegiht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(y):\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(y),y)\n",
    "    weight = {0:class_weights[0],1:class_weights[1]}\n",
    "    return (weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5338586555035706, 1: 7.883636363636364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=731     0\n",
      "1767    0\n",
      "1489    0\n",
      "2288    0\n",
      "3659    0\n",
      "       ..\n",
      "4426    0\n",
      "466     0\n",
      "3092    0\n",
      "3772    0\n",
      "860     0\n",
      "Name: Bankrupt, Length: 4336, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "class_w = get_class_weight(y_train)\n",
    "print(class_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get 0 weighted 0.533 in the data, and 1 weighted 7.883 which means the data is extremely oversampling. Since we have too much 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: randomforestclassifier class balanced Acccuracy=0.5691\n",
      "\n",
      "Model: randomforestclassifier in sample score=1.0000\n",
      "\n",
      "Model: randomforestclassifier avg cross validation score=0.9426\n",
      "\n",
      "Model: randomforestclassifier Accuracy: 92.95%, Recall 15.15%, Precision 45.45%\n"
     ]
    }
   ],
   "source": [
    "model = rf.set_params(randomforestclassifier__class_weight=class_w)\n",
    "get_score(model,\"randomforestclassifier\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression has some improvements on balanced accuracy, recall, and precision. I hope it would work the same for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression class balanced Acccuracy=0.7656\n",
      "\n",
      "Model: Logistic Regression in sample score=0.8222\n",
      "\n",
      "Model: Logistic Regression avg cross validation score=0.8109\n",
      "\n",
      "Model: Logistic Regression Accuracy: 79.88%, Recall 72.73%, Precision 21.43%\n"
     ]
    }
   ],
   "source": [
    "model = clf.set_params(logisticregression__class_weight=class_w)\n",
    "get_score(model,\"Logistic Regression\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM, balanced accuracy increased, out sample accuracy decreased by 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Classification class balanced Acccuracy=0.7549\n",
      "\n",
      "Model: Support Vector Classification in sample score=0.8406\n",
      "\n",
      "Model: Support Vector Classification avg cross validation score=0.8367\n",
      "\n",
      "Model: Support Vector Classification Accuracy: 80.50%, Recall 69.70%, Precision 21.50%\n"
     ]
    }
   ],
   "source": [
    "model = svc.set_params(svc__class_weight=class_w)\n",
    "get_score(model,\"Support Vector Classification\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For gradient descent, all scores have been decreased after adding sample weights, so maybe sample weight has conflict with some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Descent class balanced Acccuracy=0.7178\n",
      "\n",
      "Model: Gradient Descent in sample score=0.7399\n",
      "\n",
      "Model: Gradient Descent avg cross validation score=0.7179\n",
      "\n",
      "Model: Gradient Descent Accuracy: 70.95%, Recall 72.73%, Precision 15.48%\n"
     ]
    }
   ],
   "source": [
    "model = sgd.set_params(sgdclassifier__class_weight=class_w)\n",
    "get_score(model, \"Gradient Descent\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Gradinet Boosting Classifier does not have parameter of class weight. I am going to skip it.\n",
    "performs worse than before. I guess that's because GBC already handles imbalanced data, so it has some conflicts with sample weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: randomforestclassifier class balanced Acccuracy=0.5691\n",
      "\n",
      "Model: randomforestclassifier in sample score=1.0000\n",
      "\n",
      "Model: randomforestclassifier avg cross validation score=0.9426\n",
      "\n",
      "Model: randomforestclassifier Accuracy: 92.95%, Recall 15.15%, Precision 45.45%\n"
     ]
    }
   ],
   "source": [
    "model = rf.set_params(randomforestclassifier__class_weight=class_w)\n",
    "get_score(model,\"randomforestclassifier\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "Since the data have 64 different features, maybe some of the feature are not relevant to bankrupcy, so by deleting those feature I hope to increase the accuracy score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X27     0.026 +/- 0.002\n",
      "X46     0.015 +/- 0.001\n",
      "X35     0.012 +/- 0.001\n",
      "X21     0.007 +/- 0.001\n",
      "X41     0.007 +/- 0.001\n",
      "X56     0.006 +/- 0.001\n",
      "X34     0.006 +/- 0.001\n",
      "X24     0.006 +/- 0.001\n",
      "X39     0.006 +/- 0.001\n",
      "X5      0.005 +/- 0.001\n",
      "X13     0.004 +/- 0.001\n",
      "X6      0.003 +/- 0.000\n",
      "X38     0.002 +/- 0.001\n",
      "X20     0.001 +/- 0.000\n",
      "X25     0.001 +/- 0.000\n",
      "X15     0.001 +/- 0.000\n",
      "X28     0.001 +/- 0.000\n",
      "X40     0.001 +/- 0.000\n",
      "X42     0.001 +/- 0.000\n",
      "X9      0.001 +/- 0.000\n",
      "X44     0.001 +/- 0.000\n",
      "X62     0.000 +/- 0.000\n",
      "X32     0.000 +/- 0.000\n",
      "X53     0.000 +/- 0.000\n",
      "X7      0.000 +/- 0.000\n",
      "X22     0.000 +/- 0.000\n",
      "X45     0.000 +/- 0.000\n",
      "X12     0.000 +/- 0.000\n",
      "X33     0.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(gbc, X_train, y_train, n_repeats=30, random_state=42)\n",
    "for i in result.importances_mean.argsort()[::-1]:\n",
    "    if result.importances_mean[i] - 2 * result.importances_std[i] > 0:\n",
    "         print(f\"{data.columns[i]:<8}\"f\"{result.importances_mean[i]:.3f}\"f\" +/- {result.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see there are some negative and zero value in the importance value, and I think removing the feature can increase model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_feature(result, X_train, X_test):\n",
    "    neg_imp = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        if result.importances_mean[i] <= 0:\n",
    "            neg_imp.append(i)\n",
    "        \n",
    "    neg_imp = sorted(neg_imp, reverse=True)\n",
    "    for i in neg_imp:\n",
    "        X_train = X_train.drop(X_train.columns[i], axis=1)\n",
    "        X_test = X_test.drop(X_test.columns[i], axis=1)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4336, 64)\n",
      "X_test shape:  (482, 64)\n",
      "X_train shape:  (4336, 50)\n",
      "X_test shape:  (482, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "X_train, X_test = remove_feature(result, X_train, X_test)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing features with negative feature importance, we are left with less than 64 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boosting Classifier class balanced Acccuracy=0.7228\n",
      "\n",
      "Model: Gradient Boosting Classifier in sample score=0.9811\n",
      "\n",
      "Model: Gradient Boosting Classifier avg cross validation score=0.9573\n",
      "\n",
      "Model: Gradient Boosting Classifier Accuracy: 95.44%, Recall 45.45%, Precision 78.95%\n"
     ]
    }
   ],
   "source": [
    "gbc = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=42))\n",
    "get_score(gbc, \"Gradient Boosting Classifier\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used my best model which is gradient boosting classfier to fit again with the new data, and the result looks pretty good. Pricison has a 5% increases, other scores remain on the same level before. This shows that by removing some features, we successfully increased the precision of my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Classification class balanced Acccuracy=0.7516\n",
      "\n",
      "Model: Support Vector Classification in sample score=0.8367\n",
      "\n",
      "Model: Support Vector Classification avg cross validation score=0.8353\n",
      "\n",
      "Model: Support Vector Classification Accuracy: 79.88%, Recall 69.70%, Precision 20.91%\n"
     ]
    }
   ],
   "source": [
    "model = svc.set_params(svc__class_weight=class_w)\n",
    "get_score(model,\"Support Vector Classification\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after removing feature, SVM performs poorly with only 8% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines\n",
    "\n",
    "Although your notebook may contain many models (e.g., due to your iterative development)\n",
    "we will only evaluate a single model.\n",
    "So choose one (explain why !) and do the following.\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - That takes as argument a Pandas DataFrame \n",
    "        - Each row is an example on which to predict\n",
    "        - The features of the example are elements of the row\n",
    "    - Performs predictions on each example\n",
    "    - Returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model against the holdout data\n",
    "- By reading the holdout examples `X_hold` (as above)\n",
    "- Calling `y_hold_pred = MyModel(X_hold)` to get the predictions\n",
    "- Comparing the predicted values `y_hold_pred` against the true labels `y_hold` which are known only to the instructors\n",
    "\n",
    "See the following cell as an illustration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_hold = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "# Predict using MyModel\n",
    "y_hold_pred = MyModel(X_hold)\n",
    "\n",
    "# Compute metrics\n",
    "# accuracy\n",
    "accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "# recall_\n",
    "recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "# precision\n",
    "precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_hold,\n",
    "                                                                            r=recall_hold,\n",
    "                                                                            p=precision_hold\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**\n",
    "\n",
    "The holdout data is in the same format as the one we used for training\n",
    "- Except that it has no attribute for the target\n",
    "- So you will need to perform all the transformations on the holdout data\n",
    "    - As you did on the training data\n",
    "    - Including turning the string representation of numbers into actual numeric data types\n",
    "\n",
    "All of this work *must* be performed within the body of the `MyModel` routine you will write\n",
    "\n",
    "We will grade you by comparing the predictions array you create to the answers known to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def MyModel(X):    \n",
    "    X = X.loc[:, 'X1':'X64']\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    X = trans_data(X)\n",
    "    \n",
    "    svc = make_pipeline(StandardScaler(), SVC(C=0.1, kernel='linear'))\n",
    "    class_w = get_class_weight(y_train)\n",
    "    model = svc.set_params(svc__class_weight=class_w)\n",
    "\n",
    "    _ = model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for the final run\n",
    "Make the 5th-yr data as train data, and perform transformation on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv( os.path.join(DATA_DIR, \"train\", data_file) )\n",
    "\n",
    "X_train = data.loc[:,'X1':'X64']\n",
    "y_train = data.loc[:,'Bankrupt']\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_train = trans_data(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reason to choose SVM as final model\n",
    "Finally I decided to use SVC with class weights as my model because it's have the highest recall score while accuracy score is around 70%. Even though precision of the model is only 20%, but here recall is more important. If recall is low, then I may classify company that are not going to bankrupty as bankrupty whic is false positive. I think recall is more important in this problem, so I don't choose model such as gradient boosting classfier which provides high pricison and accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your work: predict and evaluate metrics on *your* test examples\n",
    "\n",
    "Although only the instructors have the correct labels for the holdout dataset, you may want\n",
    "to create your own test dataset on which to evaluate your out of sample metrics.\n",
    "\n",
    "If you choose to do so, you can evaluate your models using the same metrics that the instructors will use.\n",
    "\n",
    "- Test whether your implementation of `MyModel` works\n",
    "- See the metrics  your model produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4813    0\n",
      "4814    0\n",
      "4815    0\n",
      "4816    0\n",
      "4817    0\n",
      "Name: Bankrupt, Length: 4818, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-daa9e99ca0af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_hold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maccuracy_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mrecall_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprecision_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[0my_test_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_hold = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') \n",
    "name = \"Support Vector Classifier with class weight\"\n",
    "y_test_pred = MyModel(X_hold)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred, pos_label=1, average=\"binary\")\n",
    "precision_test = precision_score(y_test,   y_test_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,\n",
    "                                                                            r=recall_test,\n",
    "                                                                            p=precision_test\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
